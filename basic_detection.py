# -*- coding: utf-8 -*-
"""Basic_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hKWvFvDqWylone0fSKDQRy0mIyw0dOp4
"""

from google.colab import drive 
drive.mount('/content/drive')

/content/drive/My Drive/patch_faster/23843148_3mm_DCP_OS_20180222.png
/content/drive/My Drive/patch_faster/23843148_3mm_DCP_OS_20180419.png
/content/drive/My Drive/patch_faster/25022699_3mm_retina_OS_20180302.png
/content/drive/My Drive/patch_faster/26798573_3mm_DCP_OS_20190118.png
/content/drive/My Drive/patch_faster/26798573_3mm_Retina_OS_20180530.png
/content/drive/My Drive/patch_faster/21910307_3mm_DCP_OD_20190219.png


/content/drive/My Drive/patch_faster_0/26883105_3mm_SCP_OS_20180831.png
/content/drive/My Drive/patch_faster_0/26840553_3mm_Retina_OS_20180123.png
/content/drive/My Drive/patch_faster_0/26840553_3mm_DCP_OD_20190117.png
/content/drive/My Drive/patch_faster_0/26798573_3mm_DCP_OS_20181217.png
/content/drive/My Drive/patch_faster_0/25022699_3mm_retina_OS_20180302.png





import json

whole_file = "whole_coco_OCTA.json"

with open (whole_file, encoding='utf-8') as dd_file:
  whole_data = json.load(dd_file)

import copy
from copy import deepcopy

for m in range(3):
  start = 20 * m
  end = 20 * (m+1) if m < 2 else 65 

  # for train_patch
  train_files = {}
  train_files = deepcopy(whole_data)
  train_files["images"].clear()
  for i in range(start, end):
    train_files["images"].append(whole_data["images"][i])
  print(len(train_files["images"]))

  # for val_patch
  val_files = {}
  val_files = deepcopy(whole_data)
  for j in range(start, end):
    del val_files["images"][start]
  print(len(val_files["images"]))

  # making each json
  tt = "train_" + str(m) + ".json"
  vv = "val_" + str(m) + ".json"

  with open(tt, "w+t") as ttt:
    json.dump(train_files, ttt, indent='\t')  
  with open(vv, "w+t") as vvv:
    json.dump(val_files, vvv, indent='\t')

# install dependencies: 
!pip install pyyaml==5.1 pycocotools>=2.0.1
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())
!gcc --version
# opencv is pre-installed on colab

# install detectron2: (Colab has CUDA 10.1 + torch 1.6)
# See https://detectron2.readthedocs.io/tutorials/install.html for instructions
assert torch.__version__.startswith("1.6")
!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html

# Some basic setup:
# Setup detectron2 logger
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()

# import some common libraries
import numpy as np
import os, json, cv2, random
from google.colab.patches import cv2_imshow

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog

from detectron2.data.datasets import register_coco_instances

# register trainset
register_coco_instances("dataset_train0", {}, "train_0.json", "/content/drive/My Drive/new_imgs")
register_coco_instances("dataset_val0", {}, "val_0.json", "/content/drive/My Drive/new_imgs")

register_coco_instances("dataset_train1", {}, "train_1.json", "/content/drive/My Drive/new_imgs")
register_coco_instances("dataset_val1", {}, "val_1.json", "/content/drive/My Drive/new_imgs")

register_coco_instances("dataset_train2", {}, "train_2.json", "/content/drive/My Drive/new_imgs")
register_coco_instances("dataset_val2", {}, "val_2.json", "/content/drive/My Drive/new_imgs")

# register_coco_instances("dataset_train", {}, "train_patch_2.json", "/content/whole_patches")
# register_coco_instances("dataset_val", {}, "val_patch_2.json", "/content/whole_patches")

print("done")

"""### first"""

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("dataset_val0",)
cfg.DATASETS.TEST = ("dataset_train0",)
cfg.DATALOADER.NUM_WORKERS = 1
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml")  # Let training initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 4
cfg.SOLVER.BASE_LR = 0.00025

cfg.SOLVER.MAX_ITER = 1000 #adjust up if val mAP is still rising, adjust down if overfit
cfg.SOLVER.GAMMA = 0.05

cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2

cfg.TEST.EVAL_PERIOD = 500

print("done")

from detectron2.engine import DefaultTrainer
from detectron2.evaluation import COCOEvaluator

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set the testing threshold for this model
predictor = DefaultPredictor(cfg)
test_metadata = MetadataCatalog.get("dataset_train0",)

import random
from detectron2.utils.visualizer import Visualizer
from detectron2.utils.visualizer import ColorMode
import glob
from PIL import Image
import matplotlib.pyplot as plt

papa = "/content/train_0.json"
with open (papa, encoding='utf-8') as test_data:
  ddd = json.load(test_data)

name_list = []
for images in ddd["images"]:
  k = "/content/drive/My Drive/new_imgs/" + images["file_name"]
  name_list.append(k)
print(len(name_list))
print(name_list)


for imageName in glob.glob('/content/drive/My Drive/new_imgs/*png'):
  if (imageName in name_list):
    N = imageName
    im = cv2.imread(N)
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                  metadata=test_metadata, 
                  scale=1
                  )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

    original_box = []
    for box in outputs["instances"]._fields["pred_boxes"]:
      box = box.to('cpu')
      box = box.numpy()
      box = box.tolist()
      original_box.append(box)
    
    aa = cv2.imread(N, cv2.IMREAD_COLOR)
    aa = cv2.cvtColor(aa, cv2.COLOR_BGR2RGB)
    for box in original_box:
      lx, ly, rx, ry = box
      cv2.rectangle(aa, (round(lx), round(ly)), (round(rx), round(ry)), (0, 0, 255), 1)
    re = Image.fromarray(aa.astype(np.uint8))
    mm = N.split("/")[-1]
    path_save_name = "/content/drive/My Drive/normal_faster_0/" + mm
    re.save(path_save_name)
    plt.imshow(aa)

# making new

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.DATASETS.TEST = ("dataset_train0", )
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model
predictor = DefaultPredictor(cfg)
test_metadata = MetadataCatalog.get("dataset_train0",)

from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2.evaluation import COCOEvaluator, inference_on_dataset


evaluator = COCOEvaluator("dataset_train0", cfg, False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "dataset_train0")
inference_on_dataset(trainer.model, val_loader, evaluator)

"""###second"""

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("dataset_val1",)
cfg.DATASETS.TEST = ("dataset_train1",)
cfg.DATALOADER.NUM_WORKERS = 1
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml")  # Let training initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 4
cfg.SOLVER.BASE_LR = 0.00025

cfg.SOLVER.MAX_ITER = 1000 #adjust up if val mAP is still rising, adjust down if overfit
cfg.SOLVER.GAMMA = 0.05

cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2

cfg.TEST.EVAL_PERIOD = 500

print("done")

from detectron2.engine import DefaultTrainer
from detectron2.evaluation import COCOEvaluator

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model
predictor = DefaultPredictor(cfg)
test_metadata = MetadataCatalog.get("dataset_train1",)

import random
from detectron2.utils.visualizer import Visualizer
from detectron2.utils.visualizer import ColorMode
import glob
from PIL import Image
import matplotlib.pyplot as plt

papa = "/content/train_1.json"
with open (papa, encoding='utf-8') as test_data:
  ddd = json.load(test_data)

name_list = []
for images in ddd["images"]:
  k = "/content/drive/My Drive/new_imgs/" + images["file_name"]
  name_list.append(k)
print(len(name_list))
print(name_list)


for imageName in glob.glob('/content/drive/My Drive/new_imgs/*png'):
  if (imageName in name_list):
    N = imageName
    im = cv2.imread(N)
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                  metadata=test_metadata, 
                  scale=1
                  )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

    original_box = []
    for box in outputs["instances"]._fields["pred_boxes"]:
      box = box.to('cpu')
      box = box.numpy()
      box = box.tolist()
      original_box.append(box)
    
    aa = cv2.imread(N, cv2.IMREAD_COLOR)
    aa = cv2.cvtColor(aa, cv2.COLOR_BGR2RGB)
    for box in original_box:
      lx, ly, rx, ry = box
      cv2.rectangle(aa, (round(lx), round(ly)), (round(rx), round(ry)), (0, 0, 255), 1)
    re = Image.fromarray(aa.astype(np.uint8))
    mm = N.split("/")[-1]
    path_save_name = "/content/drive/My Drive/normal_faster_1/" + mm
    re.save(path_save_name)
    plt.imshow(aa)

# making new

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.DATASETS.TEST = ("dataset_train1", )
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model
predictor = DefaultPredictor(cfg)
test_metadata = MetadataCatalog.get("dataset_train1",)

from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2.evaluation import COCOEvaluator, inference_on_dataset


evaluator = COCOEvaluator("dataset_train1", cfg, False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "dataset_train1")
inference_on_dataset(trainer.model, val_loader, evaluator)

"""### third"""

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("dataset_val2",)
cfg.DATASETS.TEST = ("dataset_train2",)
cfg.DATALOADER.NUM_WORKERS = 1
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml")  # Let training initialize from model zoo
cfg.SOLVER.IMS_PER_BATCH = 4
cfg.SOLVER.BASE_LR = 0.00025

cfg.SOLVER.MAX_ITER = 1000 #adjust up if val mAP is still rising, adjust down if overfit
cfg.SOLVER.GAMMA = 0.05

cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2

cfg.TEST.EVAL_PERIOD = 500

print("done")

from detectron2.engine import DefaultTrainer
from detectron2.evaluation import COCOEvaluator

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)
trainer = DefaultTrainer(cfg) 
trainer.resume_or_load(resume=False)
trainer.train()

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85   # set the testing threshold for this model
predictor = DefaultPredictor(cfg)
test_metadata = MetadataCatalog.get("dataset_train2",)

import random
from detectron2.utils.visualizer import Visualizer
from detectron2.utils.visualizer import ColorMode
import glob
from PIL import Image
import matplotlib.pyplot as plt

papa = "/content/train_2.json"
with open (papa, encoding='utf-8') as test_data:
  ddd = json.load(test_data)

name_list = []
for images in ddd["images"]:
  k = "/content/drive/My Drive/new_imgs/" + images["file_name"]
  name_list.append(k)
print(len(name_list))
print(name_list)


for imageName in glob.glob('/content/drive/My Drive/new_imgs/*png'):
  if (imageName in name_list):
    N = imageName
    im = cv2.imread(N)
    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1],
                  metadata=test_metadata, 
                  scale=1
                  )
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
    cv2_imshow(out.get_image()[:, :, ::-1])

    original_box = []
    for box in outputs["instances"]._fields["pred_boxes"]:
      box = box.to('cpu')
      box = box.numpy()
      box = box.tolist()
      original_box.append(box)
    
    aa = cv2.imread(N, cv2.IMREAD_COLOR)
    aa = cv2.cvtColor(aa, cv2.COLOR_BGR2RGB)
    for box in original_box:
      lx, ly, rx, ry = box
      cv2.rectangle(aa, (round(lx), round(ly)), (round(rx), round(ry)), (0, 0, 255), 1)
    re = Image.fromarray(aa.astype(np.uint8))
    mm = N.split("/")[-1]
    path_save_name = "/content/drive/My Drive/normal_faster_2/" + mm
    re.save(path_save_name)
    plt.imshow(aa)

# making new

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
cfg.DATASETS.TEST = ("dataset_train2", )
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85   # set the testing threshold for this model
predictor = DefaultPredictor(cfg)
test_metadata = MetadataCatalog.get("dataset_train2",)

from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader
from detectron2.evaluation import COCOEvaluator, inference_on_dataset


evaluator = COCOEvaluator("dataset_train2", cfg, False, output_dir="./output/")
val_loader = build_detection_test_loader(cfg, "dataset_train2")
inference_on_dataset(trainer.model, val_loader, evaluator)

/content/drive/My Drive/normal_faster_2/26840553_3mm_Retina_OD_20190117.png